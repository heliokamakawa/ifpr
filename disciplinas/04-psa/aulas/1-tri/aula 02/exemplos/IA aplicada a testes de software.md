# üìò Projeto Pr√°tico: IA Aplicada a Testes de Software  
Baseado no artigo:  
**Escalante-Viteri & Mauricio (2025)**  
*Artificial Intelligence in Software Testing: A Systematic Review of a Decade of Evolution and Taxonomy*  
https://www.mdpi.com/1999-4893/18/11/717

---

## Utilizar o artigo como:

- **Base metodol√≥gica**
- **Fonte de taxonomia**
- **Guia para defini√ß√£o de protocolo**
- **Refer√™ncia para recorte experimental**

O foco n√£o √© resumir o artigo.  
O foco √© usar a base cient√≠fica/consolidada do artigo para **construir um experimento pr√°tico real**.

---

## Como podemos fazer isso?

O artigo entrega tr√™s coisas fundamentais:

1. Taxonomia de problemas em Software Testing com IA  
2. Taxonomia de vari√°veis (features usadas pelos modelos)  
3. Taxonomia de m√©tricas de avalia√ß√£o  

Seu projeto pode usar essas tr√™s dimens√µes.

---

## A Estrutura do Projeto dever√° definir claramente:

1. Um problema (baseado na taxonomia do artigo)
2. Um conjunto de vari√°veis (input do modelo)
3. Um ou mais algoritmos
4. Um conjunto de m√©tricas
5. Um protocolo experimental expl√≠cito

---

# PASSO A PASSO

## PASSO 1 ‚Äî Escolher o Problema (Taxonomia do Artigo)

Escolher UMA categoria do artigo:

- SDP ‚Üí Software Defect Prediction  
- SDD ‚Üí Software Defect Detection  
- TCM ‚Üí Test Case Management  
- ATE ‚Üí Automation & Execution  
- STC ‚Üí Test Coverage  
- STE ‚Üí Test Evaluation  

Exemplo de escolha v√°lida:

> ‚ÄúVamos trabalhar com Software Defect Prediction (SDP).‚Äù

---

## PASSO 2 ‚Äî Definir o Recorte Experimental

Voc√™ N√ÉO vai replicar o artigo inteiro.  
Voc√™ vai escolher um recorte espec√≠fico.

### Exemplos de recortes fortes:

### Caminho 1 ‚Äî Comparar algoritmos em Defect Prediction

Problema: SDP  
Vari√°veis: SCM + CQM (m√©tricas estruturais e complexidade)  
Algoritmos: Random Forest vs SVM vs MLP  
M√©tricas: F1, MCC, ROC-AUC  

Pergunta experimental:
> Qual algoritmo apresenta melhor desempenho para prever defeitos em projetos open-source?

---

### Caminho 2 ‚Äî Avaliar impacto de vari√°veis

Problema: SDP  

Modelo A ‚Üí apenas m√©tricas estruturais  
Modelo B ‚Üí m√©tricas estruturais + hist√≥rico de commits  

Pergunta experimental:
> Vari√°veis hist√≥ricas melhoram significativamente a previs√£o de defeitos?

---

### Caminho 3 ‚Äî IA para gera√ß√£o de testes

Problema: TCM ou ATE  

Gerar testes com LLM  
Medir cobertura  
Comparar com testes manuais  

Pergunta experimental:
> Testes gerados por IA atingem cobertura equivalente √† escrita manual?

---

### Caminho 4 ‚Äî Test Case Prioritization

Problema: TCM  

Treinar modelo para priorizar testes  
Executar na ordem sugerida  
Medir detec√ß√£o antecipada de falhas  

Pergunta:
> A prioriza√ß√£o por IA reduz o tempo at√© detectar defeitos cr√≠ticos?

---

# PASSO 3 ‚Äî Definir Vari√°veis (Baseado no Artigo)

Escolher explicitamente as categorias descritas:

- SCM ‚Üí Structural Code Metrics  
- CQM ‚Üí Complexity Metrics  
- EHM ‚Üí Evolutionary/Historical Metrics  
- STR ‚Üí Representa√ß√µes textuais  
- DEM ‚Üí M√©tricas din√¢micas  

‚ö† N√£o usar vari√°veis aleat√≥rias sem justificativa.

Cada vari√°vel deve ser:
- Justificada
- Descrita
- Extra√≠da corretamente

---

# PASSO 4 ‚Äî Escolher Algoritmos

Pode usar:

- Random Forest
- SVM
- MLP
- CNN (se fizer sentido)
- LLM (para gera√ß√£o de testes)

Justificar:
- Por que esse algoritmo?
- Classifica√ß√£o? Regress√£o?
- Qual problema ele resolve?

---

# PASSO 5 ‚Äî Definir M√©tricas

Basear nas categorias do artigo:

### Cl√°ssicas:
- Accuracy
- Precision
- Recall
- F1

### Avan√ßadas:
- MCC
- ROC-AUC
- Balanced Accuracy

### Espec√≠ficas de Teste:
- Cobertura
- APFD
- Mutation Score

‚Üí N√£o usar apenas Accuracy.

---

# PROTOCOLO EXPERIMENTAL (Obrigat√≥rio)

Cada grupo deve documentar:

## 1. Problema
Qual categoria do artigo foi escolhida?

## 2. Hip√≥tese
O que voc√™s querem verificar?

## 3. Dataset
Qual projeto?  
Quantos arquivos?  
Qual per√≠odo?

## 4. Vari√°veis
Quais categorias do artigo est√£o sendo usadas?

## 5. Algoritmo(s)
Configura√ß√£o e par√¢metros.

## 6. M√©tricas
Quais ser√£o usadas e por qu√™?

## 7. Execu√ß√£o
Treino/teste?  
Cross-validation?  
Split?

## 8. Resultados
Tabela comparativa.

## 9. Discuss√£o
- O que funcionou?
- O que n√£o funcionou?
- Amea√ßas √† validade?

---

# O QUE N√ÉO √â ACEITO

- Rodar modelo pronto sem justificar
- N√£o definir hip√≥tese
- N√£o relacionar com a taxonomia do artigo
- N√£o definir protocolo
- Fazer apenas implementa√ß√£o sem an√°lise

---

# Resultado Esperado

O projeto final deve mostrar:

- Capacidade de ler e aprender r√°pido os termos t√©cnicos (dominar e distinguir)
- Aplicar taxonomia na pr√°tica
- Conduzir experimento controlado (fundamentado e sem improviso)
- Avaliar qualidade de software com IA (crit√©rio e n√£o ach√¥metro)
- Discutir limita√ß√µes

---

# N√≠vel Esperado

Este √© um projeto de **Projeto de Software Avan√ßado**.  
Esperamos:

- Rigor metodol√≥gico 
- Justificativa t√©cnica
- C√≥digo organizado
- Discuss√£o cr√≠tica

---

Se necess√°rio, o professor poder√° validar o recorte experimental antes da implementa√ß√£o.

