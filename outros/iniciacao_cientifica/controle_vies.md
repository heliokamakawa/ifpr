# Controle de Vieses em Engenharia de Software

A qualidade metodolÃ³gica de um artigo nÃ£o estÃ¡ em â€œdescrever o que foi feitoâ€ â€” estÃ¡ em demonstrar que o que se fez **gera evidÃªncias vÃ¡lidas, confiÃ¡veis e generalizÃ¡veis**, isto Ã©, **livres (ou minimamente impactadas) por vieses**.

---

## O que Ã© â€œviÃ©sâ€ em Engenharia de Software

Em termos simples, **viÃ©s** Ã© qualquer distorÃ§Ã£o sistemÃ¡tica que afeta a coleta, interpretaÃ§Ã£o ou generalizaÃ§Ã£o dos resultados.  
Ele **nÃ£o Ã© apenas erro**, mas uma **tendÃªncia sistemÃ¡tica** que faz o resultado se afastar da realidade.

> **Runeson & HÃ¶st (2009):**  
> â€œO viÃ©s pode surgir em qualquer fase do estudo â€” concepÃ§Ã£o, coleta de dados, anÃ¡lise ou relato â€” e deve ser explicitado, juntamente com estratÃ©gias de mitigaÃ§Ã£o.â€

---

## Por que o controle de vieses define a validade

Detalhar e descrever como uma metodologia foi feita **nÃ£o Ã© suficiente** para tornÃ¡-la boa ou vÃ¡lida.  
A **validade da metodologia** estÃ¡ na **ausÃªncia de viÃ©s** â€” um texto detalhado, porÃ©m enviesado, apenas disfarÃ§a um problema estrutural que geralmente favorece o resultado esperado.

A validade de um artigo (isto Ã©, o quÃ£o confiÃ¡veis sÃ£o suas conclusÃµes) depende da **capacidade de isolar e mitigar vieses**.

---

## Modelo clÃ¡ssico das quatro validades  
*(Runeson & HÃ¶st, 2009; Wohlin et al., 2012)*

| Tipo de validade | QuestÃ£o central | Exemplo prÃ¡tico em ES | Risco de viÃ©s tÃ­pico |
|------------------|-----------------|------------------------|----------------------|
| **Validade de construto** | A mÃ©trica realmente mede o que se propÃµe? | Usar â€œnÃºmero de commitsâ€ como proxy de produtividade pode ser falho. | Escolha de mÃ©tricas incorretas ou ambÃ­guas. |
| **Validade interna** | Os resultados foram causados pelo que se mediu? | Uma melhoria no lead time pode ter vindo de um novo lÃ­der, nÃ£o da ferramenta. | Fatores de confusÃ£o nÃ£o controlados. |
| **Validade externa** | Pode-se generalizar o resultado? | Estudo feito em uma startup nÃ£o se aplica a empresas reguladas. | Amostra pequena, contexto Ãºnico. |
| **Validade de conclusÃ£o** | A relaÃ§Ã£o observada Ã© estatisticamente e logicamente sÃ³lida? | CorrelaÃ§Ã£o entre duas mÃ©tricas sem testar significÃ¢ncia. | Falta de anÃ¡lise estatÃ­stica adequada. |

> Essas dimensÃµes sÃ£o **complementares** â€” negligenciar uma pode comprometer todas.


## 1. Validade de Construto

| **Aspecto** | **DescriÃ§Ã£o e exemplos orientativos** |
|--------------|--------------------------------------|
| **PropÃ³sito da validade** | Avaliar se **o que estÃ¡ sendo medido realmente representa o conceito teÃ³rico** que o estudo afirma investigar. Em Engenharia de Software, significa verificar se mÃ©tricas, instrumentos e critÃ©rios de observaÃ§Ã£o **capturam o fenÃ´meno real** sem distorÃ§Ãµes conceituais. |
| **Perguntas de reflexÃ£o (para orientar o aluno)** | â€¢ A mÃ©trica usada mede realmente o fenÃ´meno estudado?<br>â€¢ O conceito foi operacionalizado de forma coerente com a teoria?<br>â€¢ O instrumento usado (questionÃ¡rio, script, log) foi validado?<br>â€¢ Se outro pesquisador aplicasse o mesmo mÃ©todo, interpretaria o mesmo fenÃ´meno?<br>â€¢ HÃ¡ referÃªncias que sustentam a adequaÃ§Ã£o da mÃ©trica? |
| **Exemplos prÃ¡ticos (de diferentes tipos de pesquisa)** | ğŸ”¹ *Experimento:* usar â€œtempo de compilaÃ§Ã£oâ€ como indicador de produtividade â€” pode nÃ£o refletir eficiÃªncia de desenvolvimento.<br>ğŸ”¹ *Survey:* aplicar questionÃ¡rio sobre â€œsatisfaÃ§Ã£o com DevOpsâ€ sem testar a clareza das perguntas.<br>ğŸ”¹ *Estudo de caso:* considerar â€œquantidade de reuniÃµesâ€ como evidÃªncia de colaboraÃ§Ã£o, sem avaliar a qualidade dessas interaÃ§Ãµes.<br>ğŸ”¹ *Mapeamento sistemÃ¡tico:* classificar artigos como â€œÃ¡gilâ€ apenas por conter a palavra â€œScrumâ€. |
| **Risco de viÃ©s tÃ­pico (descriÃ§Ã£o)** | Ocorre quando hÃ¡ **inconsistÃªncia entre o construto teÃ³rico e a medida empÃ­rica**. O pesquisador acredita medir um fenÃ´meno, mas mede outro. |
| **Exemplo negativo e explicaÃ§Ã£o do erro** | *Exemplo:* â€œMedi a produtividade dos desenvolvedores pelo nÃºmero de commits por semana.â€<br>âŒ **Erro:** confunde *atividade* com *produtividade real*.<br>âš™ï¸ **Por quÃª:** commits podem incluir correÃ§Ãµes triviais, refatoraÃ§Ãµes ou testes â€” nÃ£o refletem entrega de valor. |
| **Como corrigir / boa prÃ¡tica** | â€¢ Escolher mÃ©tricas com **base teÃ³rica ou validaÃ§Ã£o prÃ©via** (ex: DORA Metrics, ISO/IEC 25010).<br>â€¢ Justificar por que a mÃ©trica representa o fenÃ´meno.<br>â€¢ Fazer **prÃ©-teste de instrumentos** (questionÃ¡rios, logs).<br>â€¢ Utilizar **triangulaÃ§Ã£o de medidas** (quantitativas + qualitativas).<br>â€¢ Citar **fontes metodolÃ³gicas** que reforcem a validade do construto. |

---

## 2. Validade Interna

| **Aspecto** | **DescriÃ§Ã£o e exemplos orientativos** |
|--------------|--------------------------------------|
| **PropÃ³sito da validade** | Avaliar se **as relaÃ§Ãµes observadas sÃ£o genuÃ­nas**, ou se foram influenciadas por fatores externos. Busca garantir que **as conclusÃµes sobre causa e efeito** sejam sustentÃ¡veis. |
| **Perguntas de reflexÃ£o (para orientar o aluno)** | â€¢ Os resultados podem ter sido causados por outro fator nÃ£o controlado?<br>â€¢ Houve mudanÃ§as no contexto (equipe, ferramenta, polÃ­tica) durante o estudo?<br>â€¢ A coleta e anÃ¡lise foram consistentes em todos os casos?<br>â€¢ As variÃ¡veis foram medidas no mesmo momento e condiÃ§Ãµes?<br>â€¢ HÃ¡ possibilidade de viÃ©s do pesquisador ou participante? |
| **Exemplos prÃ¡ticos (de diferentes tipos de pesquisa)** | ğŸ”¹ *Experimento:* aumento de produtividade coincidindo com a chegada de um novo lÃ­der tÃ©cnico.<br>ğŸ”¹ *Estudo de caso:* adoÃ§Ã£o de metodologia Ã¡gil junto com um bÃ´nus de desempenho â€” difÃ­cil separar efeitos.<br>ğŸ”¹ *Survey:* respostas enviesadas por interesse do participante em agradar o pesquisador.<br>ğŸ”¹ *Pesquisa-aÃ§Ã£o:* melhorias causadas por acompanhamento mais prÃ³ximo, nÃ£o pela intervenÃ§Ã£o em si. |
| **Risco de viÃ©s tÃ­pico (descriÃ§Ã£o)** | Ocorre quando **fatores externos ou nÃ£o controlados interferem nos resultados**, gerando falsas relaÃ§Ãµes de causa e efeito. |
| **Exemplo negativo e explicaÃ§Ã£o do erro** | *Exemplo:* â€œApÃ³s adotar integraÃ§Ã£o contÃ­nua, o time passou a entregar mais rÃ¡pido.â€<br>âŒ **Erro:** nÃ£o houve controle sobre outros fatores (mudanÃ§a de membros, aumento de experiÃªncia, novas metas).<br>âš™ï¸ **Por quÃª:** nÃ£o se pode atribuir o efeito exclusivamente Ã  ferramenta. |
| **Como corrigir / boa prÃ¡tica** | â€¢ Definir variÃ¡veis de controle.<br>â€¢ Documentar o contexto de forma completa.<br>â€¢ Aplicar **triangulaÃ§Ã£o de dados** (entrevistas, logs, observaÃ§Ãµes).<br>â€¢ Usar **grupos de comparaÃ§Ã£o** (quando possÃ­vel).<br>â€¢ Relatar claramente fatores externos que possam ter influenciado. |

---

## 3. Validade Externa

| **Aspecto** | **DescriÃ§Ã£o e exemplos orientativos** |
|--------------|--------------------------------------|
| **PropÃ³sito da validade** | Avaliar se os resultados **podem ser generalizados** para outros contextos, organizaÃ§Ãµes, tecnologias ou equipes. Trata-se da **transferibilidade dos achados**. |
| **Perguntas de reflexÃ£o (para orientar o aluno)** | â€¢ Os resultados seriam semelhantes em outro tipo de empresa, paÃ­s ou tecnologia?<br>â€¢ A amostra representa a diversidade do contexto real?<br>â€¢ Houve replicaÃ§Ã£o em mais de um ambiente?<br>â€¢ As condiÃ§Ãµes do estudo sÃ£o especÃ­ficas demais?<br>â€¢ O estudo discute suas limitaÃ§Ãµes de generalizaÃ§Ã£o? |
| **Exemplos prÃ¡ticos (de diferentes tipos de pesquisa)** | ğŸ”¹ *Estudo de caso:* resultados obtidos em uma startup aplicados indevidamente a empresas de grande porte.<br>ğŸ”¹ *Survey:* coleta de respostas apenas de desenvolvedores web e generalizaÃ§Ã£o para toda a indÃºstria.<br>ğŸ”¹ *Mapeamento sistemÃ¡tico:* base de busca restrita a uma ou duas bases (ex: IEEE e Scopus), excluindo outras Ã¡reas. |
| **Risco de viÃ©s tÃ­pico (descriÃ§Ã£o)** | Ocorre quando o pesquisador **extrapola indevidamente os resultados** para contextos que nÃ£o compartilham as mesmas caracterÃ­sticas. |
| **Exemplo negativo e explicaÃ§Ã£o do erro** | *Exemplo:* â€œOs resultados indicam que qualquer empresa que adote DevOps terÃ¡ ganhos semelhantes.â€<br>âŒ **Erro:** generalizaÃ§Ã£o sem considerar diferenÃ§as de tamanho, cultura e maturidade tÃ©cnica.<br>âš™ï¸ **Por quÃª:** estudo restrito a startups com forte autonomia de equipe. |
| **Como corrigir / boa prÃ¡tica** | â€¢ Discutir **limitaÃ§Ãµes de generalizaÃ§Ã£o** explicitamente.<br>â€¢ Usar **amostras diversas ou replicaÃ§Ãµes em mÃºltiplos contextos**.<br>â€¢ Apresentar **descriÃ§Ã£o detalhada do ambiente** para permitir avaliaÃ§Ã£o da transferibilidade.<br>â€¢ Evitar linguagem universalizante (â€œtodas as empresasâ€, â€œsempreâ€, â€œem geralâ€). |

---

## 4. Validade de ConclusÃ£o

| **Aspecto** | **DescriÃ§Ã£o e exemplos orientativos** |
|--------------|--------------------------------------|
| **PropÃ³sito da validade** | Avaliar se **as inferÃªncias e relaÃ§Ãµes entre variÃ¡veis** sÃ£o estatÃ­stica e logicamente sÃ³lidas. Trata-se de verificar se as conclusÃµes sÃ£o sustentadas pelos dados. |
| **Perguntas de reflexÃ£o (para orientar o aluno)** | â€¢ Os testes estatÃ­sticos usados sÃ£o apropriados ao tipo de dado?<br>â€¢ HÃ¡ correlaÃ§Ã£o sem causalidade?<br>â€¢ Foram verificadas as suposiÃ§Ãµes dos testes (normalidade, independÃªncia)?<br>â€¢ O tamanho da amostra Ã© suficiente para dar confianÃ§a?<br>â€¢ Resultados negativos foram reportados? |
| **Exemplos prÃ¡ticos (de diferentes tipos de pesquisa)** | ğŸ”¹ *Experimento:* aplicaÃ§Ã£o de ANOVA com amostra pequena, violando suposiÃ§Ãµes estatÃ­sticas.<br>ğŸ”¹ *Survey:* cÃ¡lculo de mÃ©dias sem verificar distribuiÃ§Ã£o dos dados.<br>ğŸ”¹ *Estudo de caso qualitativo:* afirmar conclusÃµes gerais com base em uma Ãºnica observaÃ§Ã£o.<br>ğŸ”¹ *Mapeamento sistemÃ¡tico:* contar artigos sem avaliar relevÃ¢ncia e evidÃªncia. |
| **Risco de viÃ©s tÃ­pico (descriÃ§Ã£o)** | Ocorre quando **as inferÃªncias nÃ£o sÃ£o sustentadas pelos dados**, seja por erro estatÃ­stico, anÃ¡lise superficial ou falta de triangulaÃ§Ã£o. |
| **Exemplo negativo e explicaÃ§Ã£o do erro** | *Exemplo:* â€œHouve correlaÃ§Ã£o de 0,6 entre commits e bugs, logo aumentar commits reduz defeitos.â€<br>âŒ **Erro:** inferÃªncia causal indevida.<br>âš™ï¸ **Por quÃª:** correlaÃ§Ã£o nÃ£o implica causalidade; outras variÃ¡veis podem interferir. |
| **Como corrigir / boa prÃ¡tica** | â€¢ Utilizar testes estatÃ­sticos adequados e reportar pressupostos.<br>â€¢ Informar **p-valores, intervalos de confianÃ§a e tamanho de efeito**.<br>â€¢ Incluir **anÃ¡lise de sensibilidade** (testar resultados sob diferentes condiÃ§Ãµes).<br>â€¢ Em estudos qualitativos, aplicar **validaÃ§Ã£o cruzada** e **triangulaÃ§Ã£o**.<br>â€¢ Reportar resultados neutros ou negativos â€” eles tambÃ©m tÃªm valor cientÃ­fico. |

---

## ğŸ§  Dica geral aos alunos

> Nenhum estudo Ã© â€œsem viÃ©sâ€.  
> O que define qualidade Ã© **reconhecer onde os vieses podem ocorrer** e **demonstrar como foram mitigados**.  
> Um bom pesquisador nÃ£o esconde limitaÃ§Ãµes â€” ele as explica, controla e aprende com elas.

---

## Onde o viÃ©s aparece (por fase do estudo)

| Etapa do estudo | Principais fontes de viÃ©s | Como mitigar |
|-----------------|---------------------------|---------------|
| **Planejamento** | Escolha de hipÃ³tese guiada por expectativa; desenho inadequado | RevisÃ£o de literatura sistemÃ¡tica; protocolo prÃ©vio; registro pÃºblico (ex: OSF) |
| **Coleta de dados** | Amostra por conveniÃªncia; instrumentos nÃ£o validados; efeito Hawthorne | CritÃ©rios explÃ­citos de inclusÃ£o/exclusÃ£o; piloto de instrumentos; coleta cega ou automÃ¡tica |
| **AnÃ¡lise** | SeleÃ§Ã£o de resultados que â€œconfirmamâ€ a hipÃ³tese; cherry-picking | Definir anÃ¡lise *a priori*; reportar todos os resultados; usar triangulaÃ§Ã£o |
| **InterpretaÃ§Ã£o** | GeneralizaÃ§Ã£o indevida; causalidade sem base experimental | Discutir limites do contexto; evitar inferÃªncia causal em dados correlacionais |
| **Relato** | PublicaÃ§Ã£o seletiva de resultados positivos; omissÃ£o de ameaÃ§as Ã  validade | TransparÃªncia total; seÃ§Ã£o â€œThreats to Validityâ€ obrigatÃ³ria |

---

## EstratÃ©gias formais de mitigaÃ§Ã£o (com base em literatura de ES)

### ğŸ”¹ Planejamento
- Protocolo prÃ©vio documentado (Kitchenham, 2007): define perguntas, mÃ©todos e critÃ©rios antes da coleta.  
- TriangulaÃ§Ã£o teÃ³rica: cruzar conceitos de fontes diversas para evitar visÃ£o Ãºnica.  
- Treinamento e padronizaÃ§Ã£o dos aplicadores (se houver entrevistas ou observaÃ§Ãµes).  

### ğŸ”¹ Coleta de dados
- Amostragem sistemÃ¡tica (ou justificativa robusta para conveniÃªncia).  
- Instrumentos validados (prÃ©-teste, consistÃªncia interna, revisÃ£o de especialistas).  
- AnonimizaÃ§Ã£o e neutralidade â€” evitar influÃªncia de hierarquias organizacionais no comportamento dos respondentes.  

### ğŸ”¹ AnÃ¡lise
- TriangulaÃ§Ã£o de mÃ©todos (quantitativo + qualitativo; ex: mÃ©tricas + entrevistas).  
- ValidaÃ§Ã£o cruzada de anÃ¡lises (dois avaliadores independentes em codificaÃ§Ã£o qualitativa).  
- AnÃ¡lise de sensibilidade (testar impacto de remover casos extremos ou outliers).  

### ğŸ”¹ InterpretaÃ§Ã£o
- Discutir alternativas explicativas: â€œoutros fatores que poderiam gerar o mesmo resultadoâ€.  
- Evitar extrapolaÃ§Ãµes nÃ£o sustentadas (principal falha em estudos de caso e mapeamentos).  

### ğŸ”¹ Relato e transparÃªncia
- Sempre incluir a seÃ§Ã£o **â€œThreats to Validityâ€** organizada nas quatro dimensÃµes.  
  > ğŸ”¹ Revisores buscam explicitamente esse subtÃ­tulo em artigos de ES.  
- Fornecer repositÃ³rio pÃºblico com scripts, dados e protocolos (â€œreplication packageâ€).  
- Explicitar limitaÃ§Ãµes, sem tentar disfarÃ§Ã¡-las â€” transparÃªncia Ã© sinal de maturidade cientÃ­fica.

---

## Como um avaliador pensa sobre viÃ©s

Um bom revisor de ES **nÃ£o penaliza** o artigo por â€œter viÃ©sâ€ (todo estudo tem),  
mas sim por **nÃ£o demonstrar consciÃªncia e controle sobre ele**.

> **Pensamento tÃ­pico de avaliador:**  
> â€œO autor identificou onde o estudo poderia falhar, e mostrou como tentou reduzir isso?  
> Mesmo que o viÃ©s exista, estÃ¡ sob controle e reconhecido?â€

Revisores valorizam **reflexÃµes honestas sobre limitaÃ§Ãµes e validade** â€”  
isso distingue um artigo **maduro e cientÃ­fico** de um **ingÃªnuo e descritivo**.

---

## Guia de AvaliaÃ§Ã£o de Vieses em Engenharia de Software

| DimensÃ£o de Validade | Pergunta central do avaliador | Exemplos tÃ­picos de viÃ©s | EstratÃ©gias de mitigaÃ§Ã£o esperadas | Indicador de maturidade metodolÃ³gica |
|----------------------|--------------------------------|---------------------------|------------------------------------|--------------------------------------|
| **Validade de Construto** | â€œO que o autor estÃ¡ medindo representa o fenÃ´meno real?â€ | Uso de mÃ©tricas proxy sem validaÃ§Ã£o (ex: nÂº de commits = produtividade); questionÃ¡rios sem teste piloto; variÃ¡veis mal definidas. | DefiniÃ§Ã£o operacional das mÃ©tricas; validaÃ§Ã£o cruzada; revisÃ£o de especialistas; prÃ©-teste de instrumentos. | MÃ©tricas ou instrumentos validados e claramente justificados. |
| **Validade Interna** | â€œO resultado foi realmente causado pela variÃ¡vel estudada?â€ | ConfusÃ£o entre fatores (ex: mudanÃ§a de gestor, atualizaÃ§Ã£o de ferramenta, nova polÃ­tica de time). | Controle experimental, desenho quasi-experimental; triangulaÃ§Ã£o; grupos de comparaÃ§Ã£o. | ExplicitaÃ§Ã£o de fatores de confusÃ£o e estratÃ©gias de controle. |
| **Validade Externa** | â€œEsses resultados se aplicam a outros contextos?â€ | Amostra restrita a uma empresa; ausÃªncia de replicaÃ§Ã£o; contexto atÃ­pico. | Justificativa da amostra; replicaÃ§Ã£o multicontexto; discussÃ£o clara de limitaÃ§Ãµes. | DiscussÃ£o realista da generalizaÃ§Ã£o + convite Ã  replicaÃ§Ã£o. |
| **Validade de ConclusÃ£o** | â€œA inferÃªncia estatÃ­stica e lÃ³gica Ã© sÃ³lida?â€ | Uso incorreto de testes estatÃ­sticos; falta de verificaÃ§Ã£o de pressupostos; interpretaÃ§Ãµes causais indevidas. | Testes apropriados; anÃ¡lise de sensibilidade; reporte de p-valores e intervalos de confianÃ§a; transparÃªncia nos dados. | CoerÃªncia entre mÃ©todo analÃ­tico e objetivos. |
| **Validade Ã‰tica (em expansÃ£o)** | â€œO estudo respeita a integridade e confidencialidade dos dados e participantes?â€ | Falta de consentimento; anonimizaÃ§Ã£o ausente; uso de dados privados sem permissÃ£o. | Parecer de Ã©tica; anonimizaÃ§Ã£o rigorosa; polÃ­ticas de privacidade documentadas. | Clareza sobre tratamento Ã©tico e sigilo dos dados. |

> **Uso prÃ¡tico:**  
> Como avaliador, pontue cada linha como *Adequado / Parcial / Fraco / Ausente* e registre uma nota explicativa.

---

## Guia para Descrever â€œAmeaÃ§as Ã  Validadeâ€ no Artigo  
*(VisÃ£o de autor â€” como demonstrar controle de viÃ©s)*

**Objetivo:** Mostrar que o pesquisador entende onde o estudo pode falhar e como tentou minimizar cada limitaÃ§Ã£o.

---

### Validade de Construto
**O que avaliar:**
- Se as mÃ©tricas realmente representam os conceitos teÃ³ricos (ex: qualidade, produtividade, satisfaÃ§Ã£o).  
- Se os instrumentos medem o que se propÃµem.  

**Como relatar:**
> â€œAs mÃ©tricas de produtividade utilizadas (commits e deploys) sÃ£o proxies amplamente usadas na literatura (Forsgren et al., 2018; Google Cloud DORA, 2023). Ainda assim, reconhecemos que nÃ£o capturam aspectos qualitativos de colaboraÃ§Ã£o.â€

**Boa prÃ¡tica:** citar fontes que validam o construto e reconhecer suas limitaÃ§Ãµes.

---

### Validade Interna
**O que avaliar:**
- Se hÃ¡ fatores de confusÃ£o ou interferÃªncias externas.  
- Se as relaÃ§Ãµes observadas sÃ£o genuÃ­nas.  

**Como relatar:**
> â€œComo o estudo ocorreu durante uma reestruturaÃ§Ã£o organizacional, reconhecemos que parte das melhorias pode estar associada a fatores humanos e nÃ£o apenas Ã  introduÃ§Ã£o da ferramenta.â€

**Boa prÃ¡tica:** listar variÃ¡veis de confusÃ£o e como foram monitoradas.

---

### Validade Externa
**O que avaliar:**
- Se os resultados podem ser generalizados.  

**Como relatar:**
> â€œO estudo foi conduzido em uma Ãºnica equipe de desenvolvimento de software financeiro; os resultados podem nÃ£o refletir prÃ¡ticas de outras indÃºstrias.â€

**Boa prÃ¡tica:** nÃ£o prometer generalizaÃ§Ã£o; sugerir replicaÃ§Ãµes.

---

### Validade de ConclusÃ£o
**O que avaliar:**
- Se as inferÃªncias sÃ£o consistentes com os dados.  

**Como relatar:**
> â€œAs correlaÃ§Ãµes encontradas indicam associaÃ§Ã£o, mas nÃ£o permitem afirmar causalidade. A anÃ¡lise estatÃ­stica utilizou teste de Spearman com p < 0,05.â€

**Boa prÃ¡tica:** evitar linguagem causal quando o estudo nÃ£o Ã© experimental.

---

### (Opcional) Validade Ã‰tica e de Reprodutibilidade
**O que avaliar:**
- TransparÃªncia, abertura de dados, anonimizaÃ§Ã£o e consentimento.  

**Como relatar:**
> â€œOs dados foram anonimizados e disponibilizados em repositÃ³rio pÃºblico (Zenodo DOI: xxx). O estudo foi aprovado pelo ComitÃª de Ã‰tica nÂ° 2025-045.â€

---

### Exemplo de fechamento da seÃ§Ã£o (modelo editorial)

> â€œReconhecemos ameaÃ§as Ã s validades de construto e externa, principalmente pela limitaÃ§Ã£o da amostra e pela natureza das mÃ©tricas.  
> Para mitigÃ¡-las, seguimos recomendaÃ§Ãµes de Runeson & HÃ¶st (2009) e Wohlin et al. (2012), aplicando triangulaÃ§Ã£o de dados e validaÃ§Ã£o cruzada entre mÃºltiplos revisores.  
> Apesar dessas limitaÃ§Ãµes, acreditamos que os resultados oferecem evidÃªncias vÃ¡lidas e Ãºteis para contextos semelhantes.â€

---

## RecomendaÃ§Ãµes adicionais
- A seÃ§Ã£o deve ser **honesta e explÃ­cita** â€” evitar frases genÃ©ricas (â€œpodem haver limitaÃ§Ãµesâ€).  
- Revisores valorizam **autocrÃ­tica tÃ©cnica**: reconhecer limitaÃ§Ã£o **aumenta credibilidade**.  
- Sempre incluir **referÃªncias metodolÃ³gicas** na prÃ³pria seÃ§Ã£o de validade.  
- Quando o artigo tiver dados pÃºblicos, adicionar o link do **replication package**.

---
